{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN in TensorFlow\n",
    "\n",
    "\n",
    "Version: https://github.com/leehomyc/cyclegan-1\n",
    "\n",
    "Data: cxr8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import load data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from data_loader import Data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cycle GAN main code and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.core.protobuf import config_pb2\n",
    "\n",
    "\"\"\"Code for training CycleGAN.\"\"\"\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy.misc import imsave\n",
    "import tensorflow as tf\n",
    "\n",
    "from losses import *\n",
    "from model import *\n",
    "from parameters import *\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CycleGAN:\n",
    "    \"\"\"The CycleGAN module.\"\"\"\n",
    "\n",
    "    def __init__(self, to_restore, output_root_dir,\n",
    "                 dataset_name, checkpoint_dir, single_input_dir):\n",
    "        \n",
    "        current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        \n",
    "        self._pool_size = POOL_SIZE\n",
    "        self._lambda_a = LAMBDA_A\n",
    "        self._lambda_b = LAMBDA_B\n",
    "        self._output_dir = os.path.join(output_root_dir, current_time)\n",
    "        \n",
    "        self._images_train = os.path.join(self._output_dir, 'imgs_train')\n",
    "        self._images_val = os.path.join(self._output_dir, 'imgs_val')\n",
    "        self._images_test = os.path.join(self._output_dir, 'imgs_test')\n",
    "        \n",
    "        self._num_imgs_to_save = SAVE_IMAGES \n",
    "        self._to_restore = to_restore\n",
    "        self._base_lr = BASE_LR\n",
    "        self._max_step = MAX_STEP\n",
    "        self.generator_frequency = GEN_FREQ\n",
    "        \n",
    "        self._network_version = NET_VERSION\n",
    "        self._dataset_name = dataset_name\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._do_flipping = DO_FLIPPING\n",
    "        self._skip = SKIP\n",
    "        \n",
    "        self.batch_size = BATCH_SIZE\n",
    "\n",
    "        self.fake_images_A = np.zeros(\n",
    "            (self._pool_size, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH,\n",
    "             IMG_CHANNELS)\n",
    "        )\n",
    "        self.fake_images_B = np.zeros(\n",
    "            (self._pool_size, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH,\n",
    "             IMG_CHANNELS)\n",
    "        )\n",
    "\n",
    "    def model_setup(self):\n",
    "        \"\"\"\n",
    "        This function sets up the model to train.\n",
    "\n",
    "        self.input_A/self.input_B -> Set of training images.\n",
    "        self.fake_A/self.fake_B -> Generated images by corresponding generator\n",
    "        of input_A and input_B\n",
    "        self.lr -> Learning rate variable\n",
    "        self.cyc_A/ self.cyc_B -> Images generated after feeding\n",
    "        self.fake_A/self.fake_B to corresponding generator.\n",
    "        This is use to calculate cyclic loss\n",
    "        \"\"\"\n",
    "        self.input_a = tf.placeholder(\n",
    "            tf.float32, [\n",
    "                None,\n",
    "                IMG_WIDTH,\n",
    "                IMG_HEIGHT,\n",
    "                IMG_CHANNELS\n",
    "            ], name=\"input_A\")\n",
    "        self.input_b = tf.placeholder(\n",
    "            tf.float32, [\n",
    "                None,\n",
    "                IMG_WIDTH,\n",
    "                IMG_HEIGHT,\n",
    "                IMG_CHANNELS\n",
    "            ], name=\"input_B\")\n",
    "\n",
    "        self.fake_pool_A = tf.placeholder(\n",
    "            tf.float32, [\n",
    "                None,\n",
    "                IMG_WIDTH,\n",
    "                IMG_HEIGHT,\n",
    "                IMG_CHANNELS\n",
    "            ], name=\"fake_pool_A\")\n",
    "        self.fake_pool_B = tf.placeholder(\n",
    "            tf.float32, [\n",
    "                None,\n",
    "                IMG_WIDTH,\n",
    "                IMG_HEIGHT,\n",
    "                IMG_CHANNELS\n",
    "            ], name=\"fake_pool_B\")\n",
    "\n",
    "        self.global_step = slim.get_or_create_global_step()\n",
    "\n",
    "        self.num_fake_inputs = 0\n",
    "\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[], name=\"lr\")\n",
    "\n",
    "        inputs = {\n",
    "            'images_a': self.input_a,\n",
    "            'images_b': self.input_b,\n",
    "            'fake_pool_a': self.fake_pool_A,\n",
    "            'fake_pool_b': self.fake_pool_B,\n",
    "        }\n",
    "\n",
    "        outputs = get_outputs(\n",
    "            inputs, network=self._network_version, skip=self._skip)\n",
    "\n",
    "        self.prob_real_a_is_real = outputs['prob_real_a_is_real']\n",
    "        self.prob_real_b_is_real = outputs['prob_real_b_is_real']\n",
    "        self.fake_images_a = outputs['fake_images_a']\n",
    "        self.fake_images_b = outputs['fake_images_b']\n",
    "        self.prob_fake_a_is_real = outputs['prob_fake_a_is_real']\n",
    "        self.prob_fake_b_is_real = outputs['prob_fake_b_is_real']\n",
    "\n",
    "        self.cycle_images_a = outputs['cycle_images_a']\n",
    "        self.cycle_images_b = outputs['cycle_images_b']\n",
    "\n",
    "        self.prob_fake_pool_a_is_real = outputs['prob_fake_pool_a_is_real']\n",
    "        self.prob_fake_pool_b_is_real = outputs['prob_fake_pool_b_is_real']\n",
    "\n",
    "    def compute_losses(self):\n",
    "        \"\"\"\n",
    "        In this function we are defining the variables for loss calculations\n",
    "        and training model.\n",
    "\n",
    "        d_loss_A/d_loss_B -> loss for discriminator A/B\n",
    "        g_loss_A/g_loss_B -> loss for generator A/B\n",
    "        *_trainer -> Various trainer for above loss functions\n",
    "        *_summ -> Summary variables for above loss functions\n",
    "        \"\"\"\n",
    "        cycle_consistency_loss_a = \\\n",
    "            self._lambda_a * cycle_consistency_loss(\n",
    "                real_images=self.input_a, generated_images=self.cycle_images_a,\n",
    "            )\n",
    "        cycle_consistency_loss_b = \\\n",
    "            self._lambda_b * cycle_consistency_loss(\n",
    "                real_images=self.input_b, generated_images=self.cycle_images_b,\n",
    "            )\n",
    "\n",
    "        lsgan_loss_a = lsgan_loss_generator(self.prob_fake_a_is_real)\n",
    "        lsgan_loss_b = lsgan_loss_generator(self.prob_fake_b_is_real)\n",
    "\n",
    "        g_loss_A = \\\n",
    "            cycle_consistency_loss_a + cycle_consistency_loss_b + lsgan_loss_b\n",
    "        g_loss_B = \\\n",
    "            cycle_consistency_loss_b + cycle_consistency_loss_a + lsgan_loss_a\n",
    "\n",
    "        d_loss_A = lsgan_loss_discriminator(\n",
    "            prob_real_is_real=self.prob_real_a_is_real,\n",
    "            prob_fake_is_real=self.prob_fake_pool_a_is_real,\n",
    "        )\n",
    "        d_loss_B = lsgan_loss_discriminator(\n",
    "            prob_real_is_real=self.prob_real_b_is_real,\n",
    "            prob_fake_is_real=self.prob_fake_b_is_real,\n",
    "        )\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate, beta1=0.5)\n",
    "\n",
    "        self.model_vars = tf.trainable_variables()\n",
    "\n",
    "        d_A_vars = [var for var in self.model_vars if 'd_A' in var.name]\n",
    "        g_A_vars = [var for var in self.model_vars if 'g_A' in var.name]\n",
    "        d_B_vars = [var for var in self.model_vars if 'd_B' in var.name]\n",
    "        g_B_vars = [var for var in self.model_vars if 'g_B' in var.name]\n",
    "\n",
    "        self.d_A_trainer = optimizer.minimize(d_loss_A, var_list=d_A_vars)\n",
    "        self.d_B_trainer = optimizer.minimize(d_loss_B, var_list=d_B_vars)\n",
    "        self.g_A_trainer = optimizer.minimize(g_loss_A, var_list=g_A_vars)\n",
    "        self.g_B_trainer = optimizer.minimize(g_loss_B, var_list=g_B_vars)\n",
    "\n",
    "        for var in self.model_vars:\n",
    "            print(var.name)\n",
    "\n",
    "        # Summary variables for tensorboard training\n",
    "        self.g_A_loss_summ = tf.summary.scalar(\"g_A_loss\", g_loss_A)\n",
    "        self.g_B_loss_summ = tf.summary.scalar(\"g_B_loss\", g_loss_B)\n",
    "        self.d_A_loss_summ = tf.summary.scalar(\"d_A_loss\", d_loss_A)\n",
    "        self.d_B_loss_summ = tf.summary.scalar(\"d_B_loss\", d_loss_B)\n",
    "        \n",
    "        # Summary variables for tensorboard validating\n",
    "        self.g_A_loss_summ_val = tf.summary.scalar(\"g_A_loss_val\", g_loss_A)\n",
    "        self.g_B_loss_summ_val = tf.summary.scalar(\"g_B_loss_val\", g_loss_B)\n",
    "        self.d_A_loss_summ_val = tf.summary.scalar(\"d_A_loss_val\", d_loss_A)\n",
    "        self.d_B_loss_summ_val = tf.summary.scalar(\"d_B_loss_val\", d_loss_B)\n",
    "\n",
    "    def save_images(self, sess, epoch, inpt_a, inpt_b, imgs_dir):\n",
    "        \n",
    "        \"\"\"\n",
    "        Saves input and output images.\n",
    "\n",
    "        :param sess: The session.\n",
    "        :param epoch: Currnt epoch.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not os.path.exists(imgs_dir):\n",
    "            os.makedirs(imgs_dir)\n",
    "\n",
    "        \n",
    "        with open(os.path.join(self._output_dir, 'epoch_' + str(epoch) + '.html'), 'w') as v_html:\n",
    "            \n",
    "            for i in range(0, self._num_imgs_to_save):\n",
    "                \n",
    "                print(\"Saving image {}/{}\".format(i, self._num_imgs_to_save))\n",
    "                \n",
    "\n",
    "                ################################\n",
    "                \n",
    "                '''\n",
    "                fake_A_temp,fake_B_temp,cyc_A_temp, cyc_B_temp = sess.run([\n",
    "                    self.fake_images_a,\n",
    "                    self.fake_images_b,\n",
    "                    self.cycle_images_a,\n",
    "                    self.cycle_images_b\n",
    "                ], feed_dict={\n",
    "                    self.input_a: inpt_a[i],\n",
    "                    self.input_b: inpt_b[i]\n",
    "                })\n",
    "                \n",
    "                input_names = ['inputA_', 'inputB_']\n",
    "                names = ['fakeA_','fakeB_', 'cycA_', 'cycB_']\n",
    "                \n",
    "                tensors = [fake_B_temp, fake_A_temp, cyc_A_temp, cyc_B_temp]\n",
    "                \n",
    "                '''\n",
    "                \n",
    "                fake_B_temp, cyc_A_temp = sess.run([\n",
    "                    self.fake_images_b,\n",
    "                    self.cycle_images_a,\n",
    "                ], feed_dict={\n",
    "                    self.input_a: inpt_a[i:(i+1)],\n",
    "                    self.input_b: inpt_b[i:(i+1)]\n",
    "                })\n",
    "                \n",
    "                input_names = ['inputA_', 'inputB_']\n",
    "                names = ['fakeA_','cycA_']\n",
    "                input_tensors = [inpt_a[i:(i+1)],\n",
    "                                 inpt_b[i:(i+1)]]\n",
    "                tensors = [fake_B_temp, cyc_A_temp]\n",
    "                \n",
    "\n",
    "                for name, tensor in zip(names, tensors):\n",
    "                    \n",
    "                    image_name = name + str(epoch) + \"_\" + str(i) + \".jpg\"\n",
    "                    \n",
    "                    img = output_to_img(sess, tensor[0], IMG_CHANNELS)\n",
    "                    \n",
    "                    imsave(os.path.join(imgs_dir, image_name),img)\n",
    "                    \n",
    "                    v_html.write(\"<img src=\\\"\" +\n",
    "                        os.path.join('imgs', image_name) + \"\\\">\")\n",
    "                \n",
    "                \n",
    "                if epoch==0:\n",
    "                    \n",
    "                    for name, tensor in zip(input_names, input_tensors):\n",
    "                        \n",
    "                        image_name = name + str(epoch) + \"_\" + str(i) + \".jpg\"\n",
    "                        \n",
    "                        img = output_to_img(sess, tensor[0], IMG_CHANNELS)\n",
    "                        \n",
    "                        imsave(os.path.join(imgs_dir, image_name),img)\n",
    "                        \n",
    "                        v_html.write(\"<img src=\\\"\" +\n",
    "                            os.path.join('imgs', image_name) + \"\\\">\")   \n",
    "                        \n",
    "                    \n",
    "                v_html.write(\"<br>\")\n",
    "                \n",
    "   \n",
    "\n",
    "                    \n",
    "\n",
    "    def fake_image_pool(self, num_fakes, fake, fake_pool):\n",
    "        \"\"\"\n",
    "        This function saves the generated image to corresponding\n",
    "        pool of images.\n",
    "\n",
    "        It keeps on feeling the pool till it is full and then randomly\n",
    "        selects an already stored image and replace it with new one.\n",
    "        \"\"\"\n",
    "        if num_fakes < self._pool_size:\n",
    "            fake_pool[num_fakes] = fake\n",
    "            return fake\n",
    "        else:\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                random_id = random.randint(0, self._pool_size - 1)\n",
    "                temp = fake_pool[random_id]\n",
    "                fake_pool[random_id] = fake\n",
    "                return temp\n",
    "            else:\n",
    "                return fake\n",
    "    \n",
    "    \n",
    "    def input_read(self):\n",
    "        \n",
    "        loader = Data_loader()\n",
    "        loader.build_data()\n",
    "        \n",
    "        self.a_train = loader.a_train\n",
    "        self.a_val = loader.a_val\n",
    "        self.a_test = loader.a_test\n",
    "\n",
    "        self.b_train = loader.b_train\n",
    "        self.b_val = loader.b_val\n",
    "        self.b_test = loader.b_test\n",
    "        \n",
    "        self.limitant_n = min((self.a_train.shape[0], self.b_train.shape[0]))\n",
    "        self.n_batches = int(self.limitant_n/self.batch_size)\n",
    "        \n",
    "        print('WARNING: training images are limited to size: ', self.n_batches*self.batch_size)\n",
    "        \n",
    "        print(self.a_train.shape)\n",
    "        \n",
    "        \n",
    "    def save_val_loss(self, sess, writer, epoch, i):\n",
    "                \n",
    "            lim_val = min(self.a_val.shape[0], self.b_val.shape[0])\n",
    "            index = i%lim_val\n",
    "            val_a =  self.a_val[index:index+1]\n",
    "            val_b = self.b_val[index:index+1]\n",
    "            \n",
    "            # Generate fake A\n",
    "            fake_A_temp, summary_str = sess.run(\n",
    "                            [self.fake_images_a,\n",
    "                             self.g_B_loss_summ_val],\n",
    "                            feed_dict={\n",
    "                                self.input_a:val_a,\n",
    "                                self.input_b:val_b\n",
    "                            }\n",
    "                        )\n",
    "            \n",
    "            writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "                \n",
    "            # d_A_loss\n",
    "            summary_str = sess.run(self.d_A_loss_summ_val,\n",
    "                        feed_dict={\n",
    "                            self.input_a:val_a,\n",
    "                            self.input_b:val_b,\n",
    "                            self.fake_pool_A: fake_A_temp\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "            writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "            \n",
    "            # Generate fake B\n",
    "            fake_B_temp, summary_str = sess.run(\n",
    "                            [self.fake_images_b,\n",
    "                             self.g_A_loss_summ_val],\n",
    "                            feed_dict={\n",
    "                                self.input_a:val_a,\n",
    "                                self.input_b:val_b\n",
    "                            }\n",
    "                        )\n",
    "                        \n",
    "                        \n",
    "            writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "                 \n",
    "            # d_B_loss\n",
    "            summary_str = sess.run(self.d_B_loss_summ_val,\n",
    "                        feed_dict={\n",
    "                            self.input_a:val_a,\n",
    "                            self.input_b:val_b,\n",
    "                            self.fake_pool_B:fake_B_temp\n",
    "                        }\n",
    "                    )\n",
    "                 \n",
    "            writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "            \n",
    "            return writer\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training Function.\"\"\"\n",
    "        tf.set_random_seed(1)\n",
    "        \n",
    "        # Build the network\n",
    "        self.model_setup()\n",
    "\n",
    "        # Loss function calculations\n",
    "        self.compute_losses()\n",
    "        \n",
    "        # Load data\n",
    "        self.input_read()\n",
    "        \n",
    "\n",
    "        # Initializing the global variables\n",
    "        init = (tf.global_variables_initializer(),\n",
    "                tf.local_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        \n",
    "        with tf.Session(config=config) as sess:\n",
    "            \n",
    "            sess.run(init)\n",
    "        \n",
    "            # Creates output folder\n",
    "            if not os.path.exists(self._output_dir):\n",
    "                os.makedirs(self._output_dir)\n",
    "                \n",
    "            writer = tf.summary.FileWriter(self._output_dir)\n",
    "            \n",
    "            # Restore the model to run the model from last checkpoint\n",
    "            if self._to_restore:\n",
    "                chkpt_fname = tf.train.latest_checkpoint(self._checkpoint_dir)\n",
    "                saver.restore(sess, chkpt_fname)\n",
    "                \n",
    "\n",
    "            # EPOCH LOOP FOR TRAINING\n",
    "            for epoch in range(sess.run(self.global_step), self._max_step):\n",
    "                \n",
    "                print(\"In the epoch \", epoch)\n",
    "                saver.save(sess, os.path.join(\n",
    "                    self._output_dir, \"cyclegan\"), global_step=epoch)\n",
    "                \n",
    "                # save images\n",
    "                if (epoch % 1 == 0) or (epoch == 0):\n",
    "                    self.save_images(sess, epoch, self.a_train, self.b_train, self._images_train)\n",
    "                    self.save_images(sess, epoch, self.a_val, self.b_val, self._images_val)\n",
    "                \n",
    "                \n",
    "                # Dealing with the learning rate as per the epoch number\n",
    "                if epoch < 100:\n",
    "                    curr_lr = self._base_lr\n",
    "                else:\n",
    "                    curr_lr = self._base_lr - \\\n",
    "                        self._base_lr * (epoch - 100) / 100\n",
    "\n",
    "                \n",
    "                # RUNNING THE TRAINING ON IMAGES  \n",
    "                \n",
    "                for i in range(0, self.n_batches):\n",
    "                    \n",
    "                    print(\"Processing batch {}/{}\".format(i, self.n_batches))\n",
    "                \n",
    "                    batch_a = self.a_train[i*self.batch_size:(i+1)*self.batch_size]\n",
    "                    batch_b = self.b_train[i*self.batch_size:(i+1)*self.batch_size]\n",
    "                    \n",
    "                    if (epoch % self.generator_frequency==0) or (epoch==0): \n",
    "                        # Optimizing the G_A network\n",
    "                        _, fake_B_temp, summary_str = sess.run(\n",
    "                            [self.g_A_trainer,\n",
    "                             self.fake_images_b,\n",
    "                             self.g_A_loss_summ],\n",
    "                            feed_dict={\n",
    "                                self.input_a:batch_a,\n",
    "                                self.input_b:batch_b,\n",
    "                                self.learning_rate: curr_lr\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        # Generate fake B\n",
    "                        fake_B_temp, summary_str = sess.run(\n",
    "                            [self.fake_images_b,\n",
    "                             self.g_A_loss_summ],\n",
    "                            feed_dict={\n",
    "                                self.input_a:batch_a,\n",
    "                                self.input_b:batch_b,\n",
    "                                self.learning_rate: curr_lr\n",
    "                            }\n",
    "                        )\n",
    "                        \n",
    "                        \n",
    "                    writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "\n",
    "                    fake_B_temp1 = self.fake_image_pool(\n",
    "                        self.num_fake_inputs, fake_B_temp, self.fake_images_B)\n",
    "\n",
    "                    # Optimizing the D_B network\n",
    "                    _, summary_str = sess.run(\n",
    "                        [self.d_B_trainer, self.d_B_loss_summ],\n",
    "                        feed_dict={\n",
    "                                self.input_a:batch_a,\n",
    "                                self.input_b:batch_b,\n",
    "                            self.learning_rate: curr_lr,\n",
    "                            self.fake_pool_B: fake_B_temp1\n",
    "                        }\n",
    "                    )\n",
    "                    writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "\n",
    "                    if (epoch % self.generator_frequency == 0) or (epoch==0): \n",
    "                        # Optimizing the G_B network\n",
    "                        _, fake_A_temp, summary_str = sess.run(\n",
    "                            [self.g_B_trainer,\n",
    "                             self.fake_images_a,\n",
    "                             self.g_B_loss_summ],\n",
    "                            feed_dict={\n",
    "                                self.input_a:batch_a,\n",
    "                                self.input_b:batch_b,\n",
    "                                self.learning_rate: curr_lr\n",
    "                            }\n",
    "                        )\n",
    "                    \n",
    "                    else:\n",
    "                        # Generate fake A\n",
    "                        fake_A_temp, summary_str = sess.run(\n",
    "                            [self.fake_images_a,\n",
    "                             self.g_B_loss_summ],\n",
    "                            feed_dict={\n",
    "                                self.input_a:batch_a,\n",
    "                                self.input_b:batch_b,\n",
    "                                self.learning_rate: curr_lr\n",
    "                            }\n",
    "                        )\n",
    "                        \n",
    "                    writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "\n",
    "                    fake_A_temp1 = self.fake_image_pool(\n",
    "                        self.num_fake_inputs, fake_A_temp, self.fake_images_A)\n",
    "\n",
    "                    # Optimizing the D_A network\n",
    "                    _, summary_str = sess.run(\n",
    "                        [self.d_A_trainer, self.d_A_loss_summ],\n",
    "                        feed_dict={\n",
    "                            self.input_a:batch_a,\n",
    "                            self.input_b:batch_b,\n",
    "                            self.learning_rate: curr_lr,\n",
    "                            self.fake_pool_A: fake_A_temp1\n",
    "                        }\n",
    "                    )\n",
    "                    writer.add_summary(summary_str, epoch * self.n_batches + i)\n",
    "                    \n",
    "                    if (epoch % 10) or (epoch==0):\n",
    "                        writer = self.save_val_loss(sess, writer, epoch, i)\n",
    "\n",
    "                    writer.flush()\n",
    "                    self.num_fake_inputs += 1\n",
    "\n",
    "                sess.run(tf.assign(self.global_step, epoch + 1))\n",
    "\n",
    "            writer.add_graph(sess.graph)\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Test Function.\"\"\"\n",
    "        print(\"Testing the results\")\n",
    "\n",
    "        \n",
    "        self.model_setup()\n",
    "        saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run(init)\n",
    "            \n",
    "            #loading_data\n",
    "            self.load_data(sess)\n",
    "            \n",
    "            chkpt_fname = tf.train.latest_checkpoint(self._checkpoint_dir)\n",
    "            saver.restore(sess, chkpt_fname)\n",
    "            \n",
    "            # png for direct viewing\n",
    "            self._num_imgs_to_save = min((self.a_test.shape[0], self.b_test.shape[0]))\n",
    "            self.save_images(sess, 0, self.a_test, self.b_test, self._images_test)\n",
    "\n",
    "\n",
    "            \n",
    "def main(to_train, log_dir, dataset_name, checkpoint_dir, single_input_dir):\n",
    "    \"\"\"\n",
    "\n",
    "    :param to_train: Specify whether it is training or testing. 1: training; 2:\n",
    "     resuming from latest checkpoint; 0: testing.\n",
    "    :param log_dir: The root dir to save checkpoints and imgs. The actual dir\n",
    "    is the root dir appended by the folder with the name timestamp.\n",
    "    :param config_filename: The configuration file.\n",
    "    :param checkpoint_dir: The directory that saves the latest checkpoint. It\n",
    "    only takes effect when to_train == 2.\n",
    "    :param skip: A boolean indicating whether to add skip connection between\n",
    "    input and output.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    to_restore = (to_train == 2)\n",
    "    cyclegan_model = CycleGAN(to_restore, log_dir, dataset_name, checkpoint_dir, single_input_dir)\n",
    "    \n",
    "    if to_train > 0:\n",
    "        cyclegan_model.train()\n",
    "    else:\n",
    "        cyclegan_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model/d_A/c1/Conv/weights:0\n",
      "Model/d_A/c1/Conv/biases:0\n",
      "Model/d_A/c2/Conv/weights:0\n",
      "Model/d_A/c2/Conv/biases:0\n",
      "Model/d_A/c2/instance_norm/scale:0\n",
      "Model/d_A/c2/instance_norm/offset:0\n",
      "Model/d_A/c3/Conv/weights:0\n",
      "Model/d_A/c3/Conv/biases:0\n",
      "Model/d_A/c3/instance_norm/scale:0\n",
      "Model/d_A/c3/instance_norm/offset:0\n",
      "Model/d_A/c4/Conv/weights:0\n",
      "Model/d_A/c4/Conv/biases:0\n",
      "Model/d_A/c4/instance_norm/scale:0\n",
      "Model/d_A/c4/instance_norm/offset:0\n",
      "Model/d_A/c5/Conv/weights:0\n",
      "Model/d_A/c5/Conv/biases:0\n",
      "Model/d_B/c1/Conv/weights:0\n",
      "Model/d_B/c1/Conv/biases:0\n",
      "Model/d_B/c2/Conv/weights:0\n",
      "Model/d_B/c2/Conv/biases:0\n",
      "Model/d_B/c2/instance_norm/scale:0\n",
      "Model/d_B/c2/instance_norm/offset:0\n",
      "Model/d_B/c3/Conv/weights:0\n",
      "Model/d_B/c3/Conv/biases:0\n",
      "Model/d_B/c3/instance_norm/scale:0\n",
      "Model/d_B/c3/instance_norm/offset:0\n",
      "Model/d_B/c4/Conv/weights:0\n",
      "Model/d_B/c4/Conv/biases:0\n",
      "Model/d_B/c4/instance_norm/scale:0\n",
      "Model/d_B/c4/instance_norm/offset:0\n",
      "Model/d_B/c5/Conv/weights:0\n",
      "Model/d_B/c5/Conv/biases:0\n",
      "Model/g_A/c1/Conv/weights:0\n",
      "Model/g_A/c1/Conv/biases:0\n",
      "Model/g_A/c1/instance_norm/scale:0\n",
      "Model/g_A/c1/instance_norm/offset:0\n",
      "Model/g_A/c2/Conv/weights:0\n",
      "Model/g_A/c2/Conv/biases:0\n",
      "Model/g_A/c2/instance_norm/scale:0\n",
      "Model/g_A/c2/instance_norm/offset:0\n",
      "Model/g_A/c3/Conv/weights:0\n",
      "Model/g_A/c3/Conv/biases:0\n",
      "Model/g_A/c3/instance_norm/scale:0\n",
      "Model/g_A/c3/instance_norm/offset:0\n",
      "Model/g_A/r1/c1/Conv/weights:0\n",
      "Model/g_A/r1/c1/Conv/biases:0\n",
      "Model/g_A/r1/c1/instance_norm/scale:0\n",
      "Model/g_A/r1/c1/instance_norm/offset:0\n",
      "Model/g_A/r1/c2/Conv/weights:0\n",
      "Model/g_A/r1/c2/Conv/biases:0\n",
      "Model/g_A/r1/c2/instance_norm/scale:0\n",
      "Model/g_A/r1/c2/instance_norm/offset:0\n",
      "Model/g_A/r2/c1/Conv/weights:0\n",
      "Model/g_A/r2/c1/Conv/biases:0\n",
      "Model/g_A/r2/c1/instance_norm/scale:0\n",
      "Model/g_A/r2/c1/instance_norm/offset:0\n",
      "Model/g_A/r2/c2/Conv/weights:0\n",
      "Model/g_A/r2/c2/Conv/biases:0\n",
      "Model/g_A/r2/c2/instance_norm/scale:0\n",
      "Model/g_A/r2/c2/instance_norm/offset:0\n",
      "Model/g_A/r3/c1/Conv/weights:0\n",
      "Model/g_A/r3/c1/Conv/biases:0\n",
      "Model/g_A/r3/c1/instance_norm/scale:0\n",
      "Model/g_A/r3/c1/instance_norm/offset:0\n",
      "Model/g_A/r3/c2/Conv/weights:0\n",
      "Model/g_A/r3/c2/Conv/biases:0\n",
      "Model/g_A/r3/c2/instance_norm/scale:0\n",
      "Model/g_A/r3/c2/instance_norm/offset:0\n",
      "Model/g_A/r4/c1/Conv/weights:0\n",
      "Model/g_A/r4/c1/Conv/biases:0\n",
      "Model/g_A/r4/c1/instance_norm/scale:0\n",
      "Model/g_A/r4/c1/instance_norm/offset:0\n",
      "Model/g_A/r4/c2/Conv/weights:0\n",
      "Model/g_A/r4/c2/Conv/biases:0\n",
      "Model/g_A/r4/c2/instance_norm/scale:0\n",
      "Model/g_A/r4/c2/instance_norm/offset:0\n",
      "Model/g_A/r5/c1/Conv/weights:0\n",
      "Model/g_A/r5/c1/Conv/biases:0\n",
      "Model/g_A/r5/c1/instance_norm/scale:0\n",
      "Model/g_A/r5/c1/instance_norm/offset:0\n",
      "Model/g_A/r5/c2/Conv/weights:0\n",
      "Model/g_A/r5/c2/Conv/biases:0\n",
      "Model/g_A/r5/c2/instance_norm/scale:0\n",
      "Model/g_A/r5/c2/instance_norm/offset:0\n",
      "Model/g_A/r6/c1/Conv/weights:0\n",
      "Model/g_A/r6/c1/Conv/biases:0\n",
      "Model/g_A/r6/c1/instance_norm/scale:0\n",
      "Model/g_A/r6/c1/instance_norm/offset:0\n",
      "Model/g_A/r6/c2/Conv/weights:0\n",
      "Model/g_A/r6/c2/Conv/biases:0\n",
      "Model/g_A/r6/c2/instance_norm/scale:0\n",
      "Model/g_A/r6/c2/instance_norm/offset:0\n",
      "Model/g_A/r7/c1/Conv/weights:0\n",
      "Model/g_A/r7/c1/Conv/biases:0\n",
      "Model/g_A/r7/c1/instance_norm/scale:0\n",
      "Model/g_A/r7/c1/instance_norm/offset:0\n",
      "Model/g_A/r7/c2/Conv/weights:0\n",
      "Model/g_A/r7/c2/Conv/biases:0\n",
      "Model/g_A/r7/c2/instance_norm/scale:0\n",
      "Model/g_A/r7/c2/instance_norm/offset:0\n",
      "Model/g_A/r8/c1/Conv/weights:0\n",
      "Model/g_A/r8/c1/Conv/biases:0\n",
      "Model/g_A/r8/c1/instance_norm/scale:0\n",
      "Model/g_A/r8/c1/instance_norm/offset:0\n",
      "Model/g_A/r8/c2/Conv/weights:0\n",
      "Model/g_A/r8/c2/Conv/biases:0\n",
      "Model/g_A/r8/c2/instance_norm/scale:0\n",
      "Model/g_A/r8/c2/instance_norm/offset:0\n",
      "Model/g_A/r9/c1/Conv/weights:0\n",
      "Model/g_A/r9/c1/Conv/biases:0\n",
      "Model/g_A/r9/c1/instance_norm/scale:0\n",
      "Model/g_A/r9/c1/instance_norm/offset:0\n",
      "Model/g_A/r9/c2/Conv/weights:0\n",
      "Model/g_A/r9/c2/Conv/biases:0\n",
      "Model/g_A/r9/c2/instance_norm/scale:0\n",
      "Model/g_A/r9/c2/instance_norm/offset:0\n",
      "Model/g_A/c4/Conv/weights:0\n",
      "Model/g_A/c4/Conv/biases:0\n",
      "Model/g_A/c4/instance_norm/scale:0\n",
      "Model/g_A/c4/instance_norm/offset:0\n",
      "Model/g_A/c5/Conv/weights:0\n",
      "Model/g_A/c5/Conv/biases:0\n",
      "Model/g_A/c5/instance_norm/scale:0\n",
      "Model/g_A/c5/instance_norm/offset:0\n",
      "Model/g_A/c6/Conv/weights:0\n",
      "Model/g_A/c6/Conv/biases:0\n",
      "Model/g_B/c1/Conv/weights:0\n",
      "Model/g_B/c1/Conv/biases:0\n",
      "Model/g_B/c1/instance_norm/scale:0\n",
      "Model/g_B/c1/instance_norm/offset:0\n",
      "Model/g_B/c2/Conv/weights:0\n",
      "Model/g_B/c2/Conv/biases:0\n",
      "Model/g_B/c2/instance_norm/scale:0\n",
      "Model/g_B/c2/instance_norm/offset:0\n",
      "Model/g_B/c3/Conv/weights:0\n",
      "Model/g_B/c3/Conv/biases:0\n",
      "Model/g_B/c3/instance_norm/scale:0\n",
      "Model/g_B/c3/instance_norm/offset:0\n",
      "Model/g_B/r1/c1/Conv/weights:0\n",
      "Model/g_B/r1/c1/Conv/biases:0\n",
      "Model/g_B/r1/c1/instance_norm/scale:0\n",
      "Model/g_B/r1/c1/instance_norm/offset:0\n",
      "Model/g_B/r1/c2/Conv/weights:0\n",
      "Model/g_B/r1/c2/Conv/biases:0\n",
      "Model/g_B/r1/c2/instance_norm/scale:0\n",
      "Model/g_B/r1/c2/instance_norm/offset:0\n",
      "Model/g_B/r2/c1/Conv/weights:0\n",
      "Model/g_B/r2/c1/Conv/biases:0\n",
      "Model/g_B/r2/c1/instance_norm/scale:0\n",
      "Model/g_B/r2/c1/instance_norm/offset:0\n",
      "Model/g_B/r2/c2/Conv/weights:0\n",
      "Model/g_B/r2/c2/Conv/biases:0\n",
      "Model/g_B/r2/c2/instance_norm/scale:0\n",
      "Model/g_B/r2/c2/instance_norm/offset:0\n",
      "Model/g_B/r3/c1/Conv/weights:0\n",
      "Model/g_B/r3/c1/Conv/biases:0\n",
      "Model/g_B/r3/c1/instance_norm/scale:0\n",
      "Model/g_B/r3/c1/instance_norm/offset:0\n",
      "Model/g_B/r3/c2/Conv/weights:0\n",
      "Model/g_B/r3/c2/Conv/biases:0\n",
      "Model/g_B/r3/c2/instance_norm/scale:0\n",
      "Model/g_B/r3/c2/instance_norm/offset:0\n",
      "Model/g_B/r4/c1/Conv/weights:0\n",
      "Model/g_B/r4/c1/Conv/biases:0\n",
      "Model/g_B/r4/c1/instance_norm/scale:0\n",
      "Model/g_B/r4/c1/instance_norm/offset:0\n",
      "Model/g_B/r4/c2/Conv/weights:0\n",
      "Model/g_B/r4/c2/Conv/biases:0\n",
      "Model/g_B/r4/c2/instance_norm/scale:0\n",
      "Model/g_B/r4/c2/instance_norm/offset:0\n",
      "Model/g_B/r5/c1/Conv/weights:0\n",
      "Model/g_B/r5/c1/Conv/biases:0\n",
      "Model/g_B/r5/c1/instance_norm/scale:0\n",
      "Model/g_B/r5/c1/instance_norm/offset:0\n",
      "Model/g_B/r5/c2/Conv/weights:0\n",
      "Model/g_B/r5/c2/Conv/biases:0\n",
      "Model/g_B/r5/c2/instance_norm/scale:0\n",
      "Model/g_B/r5/c2/instance_norm/offset:0\n",
      "Model/g_B/r6/c1/Conv/weights:0\n",
      "Model/g_B/r6/c1/Conv/biases:0\n",
      "Model/g_B/r6/c1/instance_norm/scale:0\n",
      "Model/g_B/r6/c1/instance_norm/offset:0\n",
      "Model/g_B/r6/c2/Conv/weights:0\n",
      "Model/g_B/r6/c2/Conv/biases:0\n",
      "Model/g_B/r6/c2/instance_norm/scale:0\n",
      "Model/g_B/r6/c2/instance_norm/offset:0\n",
      "Model/g_B/r7/c1/Conv/weights:0\n",
      "Model/g_B/r7/c1/Conv/biases:0\n",
      "Model/g_B/r7/c1/instance_norm/scale:0\n",
      "Model/g_B/r7/c1/instance_norm/offset:0\n",
      "Model/g_B/r7/c2/Conv/weights:0\n",
      "Model/g_B/r7/c2/Conv/biases:0\n",
      "Model/g_B/r7/c2/instance_norm/scale:0\n",
      "Model/g_B/r7/c2/instance_norm/offset:0\n",
      "Model/g_B/r8/c1/Conv/weights:0\n",
      "Model/g_B/r8/c1/Conv/biases:0\n",
      "Model/g_B/r8/c1/instance_norm/scale:0\n",
      "Model/g_B/r8/c1/instance_norm/offset:0\n",
      "Model/g_B/r8/c2/Conv/weights:0\n",
      "Model/g_B/r8/c2/Conv/biases:0\n",
      "Model/g_B/r8/c2/instance_norm/scale:0\n",
      "Model/g_B/r8/c2/instance_norm/offset:0\n",
      "Model/g_B/r9/c1/Conv/weights:0\n",
      "Model/g_B/r9/c1/Conv/biases:0\n",
      "Model/g_B/r9/c1/instance_norm/scale:0\n",
      "Model/g_B/r9/c1/instance_norm/offset:0\n",
      "Model/g_B/r9/c2/Conv/weights:0\n",
      "Model/g_B/r9/c2/Conv/biases:0\n",
      "Model/g_B/r9/c2/instance_norm/scale:0\n",
      "Model/g_B/r9/c2/instance_norm/offset:0\n",
      "Model/g_B/c4/Conv/weights:0\n",
      "Model/g_B/c4/Conv/biases:0\n",
      "Model/g_B/c4/instance_norm/scale:0\n",
      "Model/g_B/c4/instance_norm/offset:0\n",
      "Model/g_B/c5/Conv/weights:0\n",
      "Model/g_B/c5/Conv/biases:0\n",
      "Model/g_B/c5/instance_norm/scale:0\n",
      "Model/g_B/c5/instance_norm/offset:0\n",
      "Model/g_B/c6/Conv/weights:0\n",
      "Model/g_B/c6/Conv/biases:0\n",
      "specified target data loader:  (0, 224, 224, 1)\n",
      "0 b'DX-G'\n",
      "len : 308\n",
      "1 b'Fluorospot_Compact_FD'\n",
      "len : 3264\n",
      "2 b'DigitalDiagnost'\n",
      "len : 7095\n",
      "3 b'Essenta_DR_Compact'\n",
      "len : 71\n",
      "4 b'CXDI'\n",
      "len : 132\n",
      "5 b'PCR_Eleva'\n",
      "len : 10\n",
      "WARNING: you are not going to preprocess\n",
      "check images properties\n",
      "data size is :  (10880, 224, 224, 1)\n",
      "Data is devided into class a: Fluorospot_Compact_FD and class b: DigitalDiagnost\n",
      "WARNING: training images are limited to size:  2938\n",
      "(2938, 224, 224, 1)\n",
      "In the epoch  0\n",
      "Saving image 0/5\n",
      "Saving image 1/5\n",
      "Saving image 2/5\n",
      "Saving image 3/5\n",
      "Saving image 4/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fc8e7f8024df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hugxgan'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_input_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-59b0ffd38937>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(to_train, log_dir, dataset_name, checkpoint_dir, single_input_dir)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_train\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mcyclegan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mcyclegan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-59b0ffd38937>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# save images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-59b0ffd38937>\u001b[0m in \u001b[0;36msave_images\u001b[0;34m(self, sess, epoch, inpt_a, inpt_b, imgs_dir)\u001b[0m\n\u001b[1;32m    245\u001b[0m                         \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_CHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                         \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dataC/project_GANs/HUGxGAN_deep_learning/apply_code/cycle_GAN_artifacts_solving/helpers.py\u001b[0m in \u001b[0;36moutput_to_img\u001b[0;34m(sess, ndarray, nchannels)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrayscale_to_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 run_metadata):\n\u001b[1;32m   1296\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1358\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "to_train=1\n",
    "\n",
    "log_dir=\"./output/cyclegan_from_fluorospot_to_digital_diagnost/debug_224_size/base_to_gen_freq=\"+str(GEN_FREQ)+\"_retrain_seed_0/exp_01\"\n",
    "output_root_dir = \"./output\"\n",
    "checkpoint_dir=\"./output/cyclegan_from_fluorospot_to_digital_diagnost/debug_224_size/base_to_gen_freq=1/exp_01/20180321-161135\"\n",
    "single_input_dir= \"\"\n",
    "dataset_name = 'hugxgan'\n",
    "\n",
    "main(to_train, log_dir, dataset_name ,checkpoint_dir, single_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
